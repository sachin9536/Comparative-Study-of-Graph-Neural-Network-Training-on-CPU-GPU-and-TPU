{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VnW-jscw5Dpx",
        "outputId": "56a8c979-5dcf-42f8-a3a8-6e7ba1caa14c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.11.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2024.10.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.8.30)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch-geometric) (4.12.2)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.6.1\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.0.0+cpu.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_scatter-2.1.2%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (494 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m494.1/494.1 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_sparse-0.6.18%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_cluster-1.6.3%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (751 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m751.3/751.3 kB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.13.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-sparse) (1.26.4)\n",
            "Installing collected packages: torch-scatter, torch-sparse, torch-cluster\n",
            "Successfully installed torch-cluster-1.6.3+pt20cpu torch-scatter-2.1.2+pt20cpu torch-sparse-0.6.18+pt20cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /usr/local/lib/python3.10/dist-packages/torch_scatter/_version_cpu.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
            "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/typing.py:97: UserWarning: An issue occurred while importing 'torch-cluster'. Disabling its usage. Stacktrace: /usr/local/lib/python3.10/dist-packages/torch_cluster/_version_cpu.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
            "  warnings.warn(f\"An issue occurred while importing 'torch-cluster'. \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /usr/local/lib/python3.10/dist-packages/torch_sparse/_version_cpu.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
            "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n",
            "Downloading https://snap.stanford.edu/data/soc-sign-bitcoinotc.csv.gz\n",
            "Extracting data/BitcoinOTC-1/raw/soc-sign-bitcoinotc.csv.gz\n",
            "Processing...\n",
            "Done!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 000, Loss: 1.1718, AUC: 0.5000, F1: 0.0000\n",
            "Epoch: 001, Loss: 1.1172, AUC: 0.4999, F1: 0.0025\n",
            "Epoch: 002, Loss: 1.1096, AUC: 0.7199, F1: 0.7607\n",
            "Epoch: 003, Loss: 1.1065, AUC: 0.5025, F1: 0.9467\n",
            "Epoch: 004, Loss: 1.1036, AUC: 0.4998, F1: 0.9472\n",
            "Epoch: 005, Loss: 1.1016, AUC: 0.5091, F1: 0.9470\n",
            "Epoch: 006, Loss: 1.1000, AUC: 0.7433, F1: 0.9003\n",
            "Epoch: 007, Loss: 1.0989, AUC: 0.6461, F1: 0.4918\n",
            "Epoch: 008, Loss: 1.0979, AUC: 0.6422, F1: 0.4734\n",
            "Epoch: 009, Loss: 1.0970, AUC: 0.7152, F1: 0.6637\n",
            "Epoch: 010, Loss: 1.0960, AUC: 0.7790, F1: 0.8387\n",
            "Epoch: 011, Loss: 1.0947, AUC: 0.7768, F1: 0.9196\n",
            "Epoch: 012, Loss: 1.0937, AUC: 0.7525, F1: 0.9396\n",
            "Epoch: 013, Loss: 1.0925, AUC: 0.7760, F1: 0.9229\n",
            "Epoch: 014, Loss: 1.0911, AUC: 0.7900, F1: 0.8521\n",
            "Epoch: 015, Loss: 1.0896, AUC: 0.7660, F1: 0.7730\n",
            "Epoch: 016, Loss: 1.0880, AUC: 0.7867, F1: 0.8184\n",
            "Epoch: 017, Loss: 1.0861, AUC: 0.8079, F1: 0.8890\n",
            "Epoch: 018, Loss: 1.0840, AUC: 0.7924, F1: 0.9149\n",
            "Epoch: 019, Loss: 1.0816, AUC: 0.8014, F1: 0.9084\n",
            "Epoch: 020, Loss: 1.0791, AUC: 0.8075, F1: 0.8916\n",
            "Epoch: 021, Loss: 1.0761, AUC: 0.8070, F1: 0.8863\n",
            "Epoch: 022, Loss: 1.0728, AUC: 0.8079, F1: 0.9086\n",
            "Epoch: 023, Loss: 1.0696, AUC: 0.8033, F1: 0.9158\n",
            "Epoch: 024, Loss: 1.0649, AUC: 0.8121, F1: 0.9090\n",
            "Epoch: 025, Loss: 1.0608, AUC: 0.8165, F1: 0.8962\n",
            "Epoch: 026, Loss: 1.0559, AUC: 0.8180, F1: 0.9025\n",
            "Epoch: 027, Loss: 1.0493, AUC: 0.8086, F1: 0.9168\n",
            "Epoch: 028, Loss: 1.0439, AUC: 0.8130, F1: 0.9130\n",
            "Epoch: 029, Loss: 1.0382, AUC: 0.8110, F1: 0.9165\n",
            "Epoch: 030, Loss: 1.0311, AUC: 0.8108, F1: 0.9242\n",
            "Epoch: 031, Loss: 1.0243, AUC: 0.8188, F1: 0.9145\n",
            "Epoch: 032, Loss: 1.0192, AUC: 0.8285, F1: 0.9148\n",
            "Epoch: 033, Loss: 1.0122, AUC: 0.8204, F1: 0.9251\n",
            "Epoch: 034, Loss: 1.0031, AUC: 0.8326, F1: 0.9187\n",
            "Epoch: 035, Loss: 0.9944, AUC: 0.8275, F1: 0.9273\n",
            "Epoch: 036, Loss: 0.9855, AUC: 0.8325, F1: 0.9244\n",
            "Epoch: 037, Loss: 0.9758, AUC: 0.8307, F1: 0.9295\n",
            "Epoch: 038, Loss: 0.9749, AUC: 0.8327, F1: 0.9324\n",
            "Epoch: 039, Loss: 0.9636, AUC: 0.8349, F1: 0.9285\n",
            "Epoch: 040, Loss: 0.9556, AUC: 0.8332, F1: 0.9294\n",
            "Epoch: 041, Loss: 0.9500, AUC: 0.8467, F1: 0.9152\n",
            "Epoch: 042, Loss: 0.9425, AUC: 0.8263, F1: 0.9428\n",
            "Epoch: 043, Loss: 0.9371, AUC: 0.8459, F1: 0.9068\n",
            "Epoch: 044, Loss: 0.9253, AUC: 0.8385, F1: 0.9332\n",
            "Epoch: 045, Loss: 0.9218, AUC: 0.8326, F1: 0.9428\n",
            "Epoch: 046, Loss: 0.9107, AUC: 0.8439, F1: 0.9014\n",
            "Epoch: 047, Loss: 0.9038, AUC: 0.8399, F1: 0.9313\n",
            "Epoch: 048, Loss: 0.8980, AUC: 0.8360, F1: 0.9367\n",
            "Epoch: 049, Loss: 0.8858, AUC: 0.8484, F1: 0.9156\n",
            "Epoch: 050, Loss: 0.8745, AUC: 0.8418, F1: 0.9277\n",
            "Epoch: 051, Loss: 0.8753, AUC: 0.8392, F1: 0.9361\n",
            "Epoch: 052, Loss: 0.8657, AUC: 0.8453, F1: 0.9165\n",
            "Epoch: 053, Loss: 0.8571, AUC: 0.8426, F1: 0.9279\n",
            "Epoch: 054, Loss: 0.8492, AUC: 0.8386, F1: 0.9355\n",
            "Epoch: 055, Loss: 0.8458, AUC: 0.8483, F1: 0.9133\n",
            "Epoch: 056, Loss: 0.8418, AUC: 0.8424, F1: 0.9355\n",
            "Epoch: 057, Loss: 0.8342, AUC: 0.8415, F1: 0.9358\n",
            "Epoch: 058, Loss: 0.8296, AUC: 0.8520, F1: 0.9190\n",
            "Epoch: 059, Loss: 0.8181, AUC: 0.8424, F1: 0.9354\n",
            "Epoch: 060, Loss: 0.8106, AUC: 0.8481, F1: 0.9311\n",
            "Epoch: 061, Loss: 0.8063, AUC: 0.8493, F1: 0.9240\n",
            "Epoch: 062, Loss: 0.7990, AUC: 0.8463, F1: 0.9397\n",
            "Epoch: 063, Loss: 0.7906, AUC: 0.8522, F1: 0.9265\n",
            "Epoch: 064, Loss: 0.7892, AUC: 0.8517, F1: 0.9331\n",
            "Epoch: 065, Loss: 0.7830, AUC: 0.8483, F1: 0.9363\n",
            "Epoch: 066, Loss: 0.7712, AUC: 0.8554, F1: 0.9222\n",
            "Epoch: 067, Loss: 0.7646, AUC: 0.8479, F1: 0.9394\n",
            "Epoch: 068, Loss: 0.7608, AUC: 0.8523, F1: 0.9317\n",
            "Epoch: 069, Loss: 0.7545, AUC: 0.8509, F1: 0.9265\n",
            "Epoch: 070, Loss: 0.7520, AUC: 0.8500, F1: 0.9382\n",
            "Epoch: 071, Loss: 0.7454, AUC: 0.8520, F1: 0.9278\n",
            "Epoch: 072, Loss: 0.7410, AUC: 0.8523, F1: 0.9359\n",
            "Epoch: 073, Loss: 0.7390, AUC: 0.8491, F1: 0.9366\n",
            "Epoch: 074, Loss: 0.7303, AUC: 0.8495, F1: 0.9227\n",
            "Epoch: 075, Loss: 0.7241, AUC: 0.8503, F1: 0.9407\n",
            "Epoch: 076, Loss: 0.7196, AUC: 0.8557, F1: 0.9276\n",
            "Epoch: 077, Loss: 0.7180, AUC: 0.8552, F1: 0.9370\n",
            "Epoch: 078, Loss: 0.7188, AUC: 0.8538, F1: 0.9376\n",
            "Epoch: 079, Loss: 0.7093, AUC: 0.8541, F1: 0.9308\n",
            "Epoch: 080, Loss: 0.7052, AUC: 0.8496, F1: 0.9322\n",
            "Epoch: 081, Loss: 0.7026, AUC: 0.8491, F1: 0.9358\n",
            "Epoch: 082, Loss: 0.6946, AUC: 0.8490, F1: 0.9343\n",
            "Epoch: 083, Loss: 0.6933, AUC: 0.8541, F1: 0.9273\n",
            "Epoch: 084, Loss: 0.6923, AUC: 0.8543, F1: 0.9436\n",
            "Epoch: 085, Loss: 0.6813, AUC: 0.8577, F1: 0.9277\n",
            "Epoch: 086, Loss: 0.6813, AUC: 0.8577, F1: 0.9349\n",
            "Epoch: 087, Loss: 0.6740, AUC: 0.8534, F1: 0.9385\n",
            "Epoch: 088, Loss: 0.6702, AUC: 0.8513, F1: 0.9320\n",
            "Epoch: 089, Loss: 0.6731, AUC: 0.8541, F1: 0.9364\n",
            "Epoch: 090, Loss: 0.6656, AUC: 0.8527, F1: 0.9391\n",
            "Epoch: 091, Loss: 0.6628, AUC: 0.8554, F1: 0.9251\n",
            "Epoch: 092, Loss: 0.6574, AUC: 0.8572, F1: 0.9364\n",
            "Epoch: 093, Loss: 0.6514, AUC: 0.8575, F1: 0.9304\n",
            "Epoch: 094, Loss: 0.6546, AUC: 0.8559, F1: 0.9300\n",
            "Epoch: 095, Loss: 0.6508, AUC: 0.8574, F1: 0.9324\n",
            "Epoch: 096, Loss: 0.6573, AUC: 0.8545, F1: 0.9417\n",
            "Epoch: 097, Loss: 0.6558, AUC: 0.8566, F1: 0.9140\n",
            "Epoch: 098, Loss: 0.6504, AUC: 0.8489, F1: 0.9440\n",
            "Epoch: 099, Loss: 0.6405, AUC: 0.8534, F1: 0.9405\n",
            "Epoch: 100, Loss: 0.6401, AUC: 0.8554, F1: 0.9186\n",
            "Training completed on CPU in 28.37 seconds\n"
          ]
        }
      ],
      "source": [
        "# Install dependencies\n",
        "!pip install torch\n",
        "!pip install torch-geometric\n",
        "!pip install torch-scatter torch-sparse torch-cluster -f https://data.pyg.org/whl/torch-2.0.0+cpu.html\n",
        "\n",
        "import os.path as osp\n",
        "import torch\n",
        "from torch_geometric.datasets import BitcoinOTC\n",
        "from torch_geometric.nn import SignedGCN\n",
        "import time\n",
        "\n",
        "# Set device to CPU\n",
        "device = torch.device('cpu')\n",
        "\n",
        "# Load BitcoinOTC dataset\n",
        "name = 'BitcoinOTC-1'\n",
        "path = osp.join('data', name)\n",
        "dataset = BitcoinOTC(path, edge_window_size=1)\n",
        "\n",
        "# Prepare positive and negative edges\n",
        "pos_edge_indices, neg_edge_indices = [], []\n",
        "for data in dataset:\n",
        "    pos_edge_indices.append(data.edge_index[:, data.edge_attr > 0])\n",
        "    neg_edge_indices.append(data.edge_index[:, data.edge_attr < 0])\n",
        "\n",
        "# Move data to CPU\n",
        "pos_edge_index = torch.cat(pos_edge_indices, dim=1).to(device)\n",
        "neg_edge_index = torch.cat(neg_edge_indices, dim=1).to(device)\n",
        "\n",
        "# Build and train SignedGCN model\n",
        "model = SignedGCN(64, 64, num_layers=2, lamb=5).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "\n",
        "train_pos_edge_index, test_pos_edge_index = model.split_edges(pos_edge_index)\n",
        "train_neg_edge_index, test_neg_edge_index = model.split_edges(neg_edge_index)\n",
        "x = model.create_spectral_features(train_pos_edge_index, train_neg_edge_index).to(device)\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    z = model(x, train_pos_edge_index, train_neg_edge_index)\n",
        "    loss = model.loss(z, train_pos_edge_index, train_neg_edge_index)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "def test():\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        z = model(x, train_pos_edge_index, train_neg_edge_index)\n",
        "    return model.test(z, test_pos_edge_index, test_neg_edge_index)\n",
        "\n",
        "# Training loop with timing\n",
        "start_time = time.time()\n",
        "for epoch in range(101):\n",
        "    loss = train()\n",
        "    auc, f1 = test()\n",
        "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, AUC: {auc:.4f}, F1: {f1:.4f}')\n",
        "cpu_time = time.time() - start_time\n",
        "print(f\"Training completed on CPU in {cpu_time:.2f} seconds\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "!pip install torch\n",
        "!pip install torch-geometric\n",
        "!pip install torch-scatter torch-sparse torch-cluster -f https://data.pyg.org/whl/torch-2.0.0+cpu.html\n",
        "\n",
        "import os.path as osp\n",
        "import torch\n",
        "from torch_geometric.datasets import BitcoinOTC\n",
        "from torch_geometric.nn import SignedGCN\n",
        "import time\n",
        "\n",
        "# Set device to GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Load BitcoinOTC dataset\n",
        "name = 'BitcoinOTC-1'\n",
        "path = osp.join('data', name)\n",
        "dataset = BitcoinOTC(path, edge_window_size=1)\n",
        "\n",
        "# Prepare positive and negative edges\n",
        "pos_edge_indices, neg_edge_indices = [], []\n",
        "for data in dataset:\n",
        "    pos_edge_indices.append(data.edge_index[:, data.edge_attr > 0])\n",
        "    neg_edge_indices.append(data.edge_index[:, data.edge_attr < 0])\n",
        "\n",
        "# Move data to GPU\n",
        "pos_edge_index = torch.cat(pos_edge_indices, dim=1).to(device)\n",
        "neg_edge_index = torch.cat(neg_edge_indices, dim=1).to(device)\n",
        "\n",
        "# Build and train SignedGCN model\n",
        "model = SignedGCN(64, 64, num_layers=2, lamb=5).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "\n",
        "train_pos_edge_index, test_pos_edge_index = model.split_edges(pos_edge_index)\n",
        "train_neg_edge_index, test_neg_edge_index = model.split_edges(neg_edge_index)\n",
        "x = model.create_spectral_features(train_pos_edge_index, train_neg_edge_index).to(device)\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    z = model(x, train_pos_edge_index, train_neg_edge_index)\n",
        "    loss = model.loss(z, train_pos_edge_index, train_neg_edge_index)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "def test():\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        z = model(x, train_pos_edge_index, train_neg_edge_index)\n",
        "    return model.test(z, test_pos_edge_index, test_neg_edge_index)\n",
        "\n",
        "# Training loop with timing\n",
        "start_time = time.time()\n",
        "for epoch in range(101):\n",
        "    loss = train()\n",
        "    auc, f1 = test()\n",
        "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, AUC: {auc:.4f}, F1: {f1:.4f}')\n",
        "gpu_time = time.time() - start_time\n",
        "print(f\"Training completed on GPU in {gpu_time:.2f} seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Ea38e_X5M0V",
        "outputId": "a354ff93-c60d-482b-e20c-1a6c3894a618"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.11.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2024.10.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.8.30)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch-geometric) (4.12.2)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.6.1\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.0.0+cpu.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_scatter-2.1.2%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (494 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m494.1/494.1 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_sparse-0.6.18%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_cluster-1.6.3%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (751 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m751.3/751.3 kB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.13.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-sparse) (1.26.4)\n",
            "Installing collected packages: torch-scatter, torch-sparse, torch-cluster\n",
            "Successfully installed torch-cluster-1.6.3+pt20cpu torch-scatter-2.1.2+pt20cpu torch-sparse-0.6.18+pt20cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /usr/local/lib/python3.10/dist-packages/torch_scatter/_version_cpu.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
            "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/typing.py:97: UserWarning: An issue occurred while importing 'torch-cluster'. Disabling its usage. Stacktrace: /usr/local/lib/python3.10/dist-packages/torch_cluster/_version_cpu.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
            "  warnings.warn(f\"An issue occurred while importing 'torch-cluster'. \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /usr/local/lib/python3.10/dist-packages/torch_sparse/_version_cpu.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
            "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n",
            "Downloading https://snap.stanford.edu/data/soc-sign-bitcoinotc.csv.gz\n",
            "Extracting data/BitcoinOTC-1/raw/soc-sign-bitcoinotc.csv.gz\n",
            "Processing...\n",
            "Done!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 000, Loss: 1.1682, AUC: 0.5000, F1: 0.9473\n",
            "Epoch: 001, Loss: 1.1162, AUC: 0.6834, F1: 0.7609\n",
            "Epoch: 002, Loss: 1.1064, AUC: 0.5000, F1: 0.0000\n",
            "Epoch: 003, Loss: 1.1040, AUC: 0.5000, F1: 0.0000\n",
            "Epoch: 004, Loss: 1.1024, AUC: 0.5000, F1: 0.0000\n",
            "Epoch: 005, Loss: 1.1006, AUC: 0.5000, F1: 0.0000\n",
            "Epoch: 006, Loss: 1.0990, AUC: 0.5373, F1: 0.1994\n",
            "Epoch: 007, Loss: 1.0979, AUC: 0.7296, F1: 0.8901\n",
            "Epoch: 008, Loss: 1.0969, AUC: 0.7046, F1: 0.9471\n",
            "Epoch: 009, Loss: 1.0960, AUC: 0.6959, F1: 0.9493\n",
            "Epoch: 010, Loss: 1.0952, AUC: 0.7257, F1: 0.9401\n",
            "Epoch: 011, Loss: 1.0946, AUC: 0.7376, F1: 0.9331\n",
            "Epoch: 012, Loss: 1.0937, AUC: 0.7517, F1: 0.9291\n",
            "Epoch: 013, Loss: 1.0927, AUC: 0.7550, F1: 0.9251\n",
            "Epoch: 014, Loss: 1.0914, AUC: 0.7603, F1: 0.9103\n",
            "Epoch: 015, Loss: 1.0900, AUC: 0.7733, F1: 0.8740\n",
            "Epoch: 016, Loss: 1.0885, AUC: 0.7757, F1: 0.8461\n",
            "Epoch: 017, Loss: 1.0870, AUC: 0.7829, F1: 0.8353\n",
            "Epoch: 018, Loss: 1.0853, AUC: 0.7879, F1: 0.8609\n",
            "Epoch: 019, Loss: 1.0832, AUC: 0.7912, F1: 0.8795\n",
            "Epoch: 020, Loss: 1.0808, AUC: 0.7972, F1: 0.8805\n",
            "Epoch: 021, Loss: 1.0782, AUC: 0.8005, F1: 0.8768\n",
            "Epoch: 022, Loss: 1.0745, AUC: 0.8045, F1: 0.8933\n",
            "Epoch: 023, Loss: 1.0710, AUC: 0.8075, F1: 0.9045\n",
            "Epoch: 024, Loss: 1.0676, AUC: 0.8058, F1: 0.9178\n",
            "Epoch: 025, Loss: 1.0629, AUC: 0.8099, F1: 0.9175\n",
            "Epoch: 026, Loss: 1.0584, AUC: 0.8160, F1: 0.9039\n",
            "Epoch: 027, Loss: 1.0533, AUC: 0.8225, F1: 0.9122\n",
            "Epoch: 028, Loss: 1.0476, AUC: 0.8068, F1: 0.9325\n",
            "Epoch: 029, Loss: 1.0430, AUC: 0.8265, F1: 0.9190\n",
            "Epoch: 030, Loss: 1.0373, AUC: 0.8250, F1: 0.9173\n",
            "Epoch: 031, Loss: 1.0298, AUC: 0.8197, F1: 0.9299\n",
            "Epoch: 032, Loss: 1.0240, AUC: 0.8300, F1: 0.9157\n",
            "Epoch: 033, Loss: 1.0164, AUC: 0.8322, F1: 0.9240\n",
            "Epoch: 034, Loss: 1.0093, AUC: 0.8227, F1: 0.9340\n",
            "Epoch: 035, Loss: 0.9999, AUC: 0.8399, F1: 0.9131\n",
            "Epoch: 036, Loss: 0.9942, AUC: 0.8293, F1: 0.9286\n",
            "Epoch: 037, Loss: 0.9849, AUC: 0.8291, F1: 0.9340\n",
            "Epoch: 038, Loss: 0.9767, AUC: 0.8382, F1: 0.9236\n",
            "Epoch: 039, Loss: 0.9675, AUC: 0.8261, F1: 0.9397\n",
            "Epoch: 040, Loss: 0.9612, AUC: 0.8461, F1: 0.9152\n",
            "Epoch: 041, Loss: 0.9554, AUC: 0.8280, F1: 0.9405\n",
            "Epoch: 042, Loss: 0.9457, AUC: 0.8436, F1: 0.9290\n",
            "Epoch: 043, Loss: 0.9346, AUC: 0.8423, F1: 0.9196\n",
            "Epoch: 044, Loss: 0.9301, AUC: 0.8288, F1: 0.9448\n",
            "Epoch: 045, Loss: 0.9223, AUC: 0.8498, F1: 0.9172\n",
            "Epoch: 046, Loss: 0.9128, AUC: 0.8499, F1: 0.9318\n",
            "Epoch: 047, Loss: 0.9024, AUC: 0.8290, F1: 0.9464\n",
            "Epoch: 048, Loss: 0.8970, AUC: 0.8488, F1: 0.9233\n",
            "Epoch: 049, Loss: 0.8914, AUC: 0.8474, F1: 0.9240\n",
            "Epoch: 050, Loss: 0.8811, AUC: 0.8272, F1: 0.9479\n",
            "Epoch: 051, Loss: 0.8739, AUC: 0.8436, F1: 0.9218\n",
            "Epoch: 052, Loss: 0.8697, AUC: 0.8456, F1: 0.9227\n",
            "Epoch: 053, Loss: 0.8613, AUC: 0.8357, F1: 0.9454\n",
            "Epoch: 054, Loss: 0.8499, AUC: 0.8468, F1: 0.9276\n",
            "Epoch: 055, Loss: 0.8473, AUC: 0.8464, F1: 0.9185\n",
            "Epoch: 056, Loss: 0.8341, AUC: 0.8399, F1: 0.9390\n",
            "Epoch: 057, Loss: 0.8296, AUC: 0.8426, F1: 0.9384\n",
            "Epoch: 058, Loss: 0.8246, AUC: 0.8480, F1: 0.9174\n",
            "Epoch: 059, Loss: 0.8127, AUC: 0.8468, F1: 0.9340\n",
            "Epoch: 060, Loss: 0.8139, AUC: 0.8411, F1: 0.9389\n",
            "Epoch: 061, Loss: 0.8089, AUC: 0.8495, F1: 0.9250\n",
            "Epoch: 062, Loss: 0.7969, AUC: 0.8499, F1: 0.9283\n",
            "Epoch: 063, Loss: 0.7948, AUC: 0.8442, F1: 0.9361\n",
            "Epoch: 064, Loss: 0.7872, AUC: 0.8467, F1: 0.9338\n",
            "Epoch: 065, Loss: 0.7808, AUC: 0.8475, F1: 0.9284\n",
            "Epoch: 066, Loss: 0.7691, AUC: 0.8461, F1: 0.9346\n",
            "Epoch: 067, Loss: 0.7664, AUC: 0.8465, F1: 0.9301\n",
            "Epoch: 068, Loss: 0.7606, AUC: 0.8456, F1: 0.9283\n",
            "Epoch: 069, Loss: 0.7548, AUC: 0.8438, F1: 0.9341\n",
            "Epoch: 070, Loss: 0.7563, AUC: 0.8479, F1: 0.9295\n",
            "Epoch: 071, Loss: 0.7476, AUC: 0.8456, F1: 0.9312\n",
            "Epoch: 072, Loss: 0.7427, AUC: 0.8465, F1: 0.9294\n",
            "Epoch: 073, Loss: 0.7366, AUC: 0.8481, F1: 0.9312\n",
            "Epoch: 074, Loss: 0.7292, AUC: 0.8461, F1: 0.9332\n",
            "Epoch: 075, Loss: 0.7261, AUC: 0.8426, F1: 0.9363\n",
            "Epoch: 076, Loss: 0.7229, AUC: 0.8498, F1: 0.9316\n",
            "Epoch: 077, Loss: 0.7186, AUC: 0.8453, F1: 0.9338\n",
            "Epoch: 078, Loss: 0.7080, AUC: 0.8471, F1: 0.9336\n",
            "Epoch: 079, Loss: 0.7091, AUC: 0.8518, F1: 0.9297\n",
            "Epoch: 080, Loss: 0.7040, AUC: 0.8477, F1: 0.9335\n",
            "Epoch: 081, Loss: 0.6974, AUC: 0.8500, F1: 0.9319\n",
            "Epoch: 082, Loss: 0.6968, AUC: 0.8442, F1: 0.9332\n",
            "Epoch: 083, Loss: 0.6871, AUC: 0.8502, F1: 0.9279\n",
            "Epoch: 084, Loss: 0.6874, AUC: 0.8451, F1: 0.9377\n",
            "Epoch: 085, Loss: 0.6806, AUC: 0.8481, F1: 0.9319\n",
            "Epoch: 086, Loss: 0.6833, AUC: 0.8465, F1: 0.9336\n",
            "Epoch: 087, Loss: 0.6737, AUC: 0.8474, F1: 0.9283\n",
            "Epoch: 088, Loss: 0.6729, AUC: 0.8470, F1: 0.9356\n",
            "Epoch: 089, Loss: 0.6706, AUC: 0.8519, F1: 0.9305\n",
            "Epoch: 090, Loss: 0.6647, AUC: 0.8501, F1: 0.9355\n",
            "Epoch: 091, Loss: 0.6630, AUC: 0.8488, F1: 0.9348\n",
            "Epoch: 092, Loss: 0.6618, AUC: 0.8486, F1: 0.9310\n",
            "Epoch: 093, Loss: 0.6570, AUC: 0.8475, F1: 0.9383\n",
            "Epoch: 094, Loss: 0.6542, AUC: 0.8538, F1: 0.9204\n",
            "Epoch: 095, Loss: 0.6488, AUC: 0.8378, F1: 0.9470\n",
            "Epoch: 096, Loss: 0.6536, AUC: 0.8552, F1: 0.9155\n",
            "Epoch: 097, Loss: 0.6499, AUC: 0.8469, F1: 0.9355\n",
            "Epoch: 098, Loss: 0.6418, AUC: 0.8407, F1: 0.9426\n",
            "Epoch: 099, Loss: 0.6407, AUC: 0.8568, F1: 0.9180\n",
            "Epoch: 100, Loss: 0.6382, AUC: 0.8453, F1: 0.9380\n",
            "Training completed on GPU in 8.30 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os.path as osp\n",
        "import torch\n",
        "import torch_xla.core.xla_model as xm\n",
        "from torch_geometric.datasets import BitcoinOTC\n",
        "from torch_geometric.nn import SignedGCN\n",
        "import time\n",
        "\n",
        "device = xm.xla_device()\n",
        "\n",
        "# Load dataset\n",
        "name = 'BitcoinOTC-1'\n",
        "path = osp.join('data', name)\n",
        "dataset = BitcoinOTC(path, edge_window_size=1)\n",
        "\n",
        "# Prepare edges\n",
        "pos_edge_indices, neg_edge_indices = [], []\n",
        "for data in dataset:\n",
        "    pos_edge_indices.append(data.edge_index[:, data.edge_attr > 0])\n",
        "    neg_edge_indices.append(data.edge_index[:, data.edge_attr < 0])\n",
        "\n",
        "# Preload data onto TPU\n",
        "pos_edge_index = torch.cat(pos_edge_indices, dim=1).to(device)\n",
        "neg_edge_index = torch.cat(neg_edge_indices, dim=1).to(device)\n",
        "\n",
        "# Model setup\n",
        "model = SignedGCN(64, 64, num_layers=2, lamb=5).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "train_pos_edge_index, test_pos_edge_index = model.split_edges(pos_edge_index)\n",
        "train_neg_edge_index, test_neg_edge_index = model.split_edges(neg_edge_index)\n",
        "x = model.create_spectral_features(train_pos_edge_index, train_neg_edge_index).to(device)\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    z = model(x, train_pos_edge_index, train_neg_edge_index)\n",
        "    loss = model.loss(z, train_pos_edge_index, train_neg_edge_index)\n",
        "    loss.backward()\n",
        "    xm.optimizer_step(optimizer)\n",
        "    xm.mark_step()  # Signal TPU computation completion\n",
        "    return loss.item()\n",
        "\n",
        "def test():\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        z = model(x, train_pos_edge_index, train_neg_edge_index)\n",
        "    return model.test(z, test_pos_edge_index, test_neg_edge_index)\n",
        "\n",
        "# Training loop with timing\n",
        "start_time = time.time()\n",
        "for epoch in range(101):\n",
        "    loss = train()\n",
        "    auc, f1 = test()\n",
        "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, AUC: {auc:.4f}, F1: {f1:.4f}')\n",
        "tpu_time = time.time() - start_time\n",
        "print(f\"Training completed on TPU in {tpu_time:.2f} seconds\")\n",
        "\n",
        "\n",
        "# Set device to CPU\n",
        "device = torch.device('cpu')\n",
        "# Set device to GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# Preload data onto TPU\n",
        "pos_edge_index = torch.cat(pos_edge_indices, dim=1).to(device)\n",
        "neg_edge_index = torch.cat(neg_edge_indices, dim=1).to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlbcfzB36CeI",
        "outputId": "591bfe8b-e2af-4362-ff80-a38e82366fb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 000, Loss: 1.1946, AUC: 0.5000, F1: 0.0000\n",
            "Epoch: 001, Loss: 1.1260, AUC: 0.5023, F1: 0.0201\n",
            "Epoch: 002, Loss: 1.1125, AUC: 0.5382, F1: 0.9354\n",
            "Epoch: 003, Loss: 1.1082, AUC: 0.4999, F1: 0.9473\n",
            "Epoch: 004, Loss: 1.1058, AUC: 0.4999, F1: 0.9473\n",
            "Epoch: 005, Loss: 1.1039, AUC: 0.5382, F1: 0.9483\n",
            "Epoch: 006, Loss: 1.1017, AUC: 0.6414, F1: 0.7568\n",
            "Epoch: 007, Loss: 1.1001, AUC: 0.5733, F1: 0.4106\n",
            "Epoch: 008, Loss: 1.0988, AUC: 0.6578, F1: 0.6562\n",
            "Epoch: 009, Loss: 1.0979, AUC: 0.7281, F1: 0.8379\n",
            "Epoch: 010, Loss: 1.0970, AUC: 0.7353, F1: 0.8747\n",
            "Epoch: 011, Loss: 1.0962, AUC: 0.7378, F1: 0.8730\n",
            "Epoch: 012, Loss: 1.0952, AUC: 0.7592, F1: 0.8803\n",
            "Epoch: 013, Loss: 1.0944, AUC: 0.7663, F1: 0.8905\n",
            "Epoch: 014, Loss: 1.0935, AUC: 0.7569, F1: 0.9056\n",
            "Epoch: 015, Loss: 1.0925, AUC: 0.7560, F1: 0.9148\n",
            "Epoch: 016, Loss: 1.0914, AUC: 0.7577, F1: 0.9102\n",
            "Epoch: 017, Loss: 1.0902, AUC: 0.7779, F1: 0.8936\n",
            "Epoch: 018, Loss: 1.0887, AUC: 0.7914, F1: 0.8638\n",
            "Epoch: 019, Loss: 1.0870, AUC: 0.7950, F1: 0.8683\n",
            "Epoch: 020, Loss: 1.0850, AUC: 0.7804, F1: 0.8988\n",
            "Epoch: 021, Loss: 1.0822, AUC: 0.7637, F1: 0.9177\n",
            "Epoch: 022, Loss: 1.0797, AUC: 0.7682, F1: 0.9192\n",
            "Epoch: 023, Loss: 1.0763, AUC: 0.7861, F1: 0.9047\n",
            "Epoch: 024, Loss: 1.0726, AUC: 0.7921, F1: 0.8983\n",
            "Epoch: 025, Loss: 1.0687, AUC: 0.7936, F1: 0.9023\n",
            "Epoch: 026, Loss: 1.0649, AUC: 0.8010, F1: 0.9035\n",
            "Epoch: 027, Loss: 1.0598, AUC: 0.8024, F1: 0.9088\n",
            "Epoch: 028, Loss: 1.0555, AUC: 0.8054, F1: 0.9087\n",
            "Epoch: 029, Loss: 1.0470, AUC: 0.7961, F1: 0.9234\n",
            "Epoch: 030, Loss: 1.0429, AUC: 0.8066, F1: 0.9152\n",
            "Epoch: 031, Loss: 1.0343, AUC: 0.8083, F1: 0.9157\n",
            "Epoch: 032, Loss: 1.0262, AUC: 0.8046, F1: 0.9244\n",
            "Epoch: 033, Loss: 1.0179, AUC: 0.8174, F1: 0.9129\n",
            "Epoch: 034, Loss: 1.0120, AUC: 0.8180, F1: 0.9209\n",
            "Epoch: 035, Loss: 1.0001, AUC: 0.8203, F1: 0.9220\n",
            "Epoch: 036, Loss: 0.9930, AUC: 0.8239, F1: 0.9102\n",
            "Epoch: 037, Loss: 0.9866, AUC: 0.8054, F1: 0.9344\n",
            "Epoch: 038, Loss: 0.9772, AUC: 0.8263, F1: 0.8988\n",
            "Epoch: 039, Loss: 0.9653, AUC: 0.8172, F1: 0.9321\n",
            "Epoch: 040, Loss: 0.9591, AUC: 0.8175, F1: 0.9240\n",
            "Epoch: 041, Loss: 0.9478, AUC: 0.8242, F1: 0.9046\n",
            "Epoch: 042, Loss: 0.9431, AUC: 0.8175, F1: 0.9311\n",
            "Epoch: 043, Loss: 0.9288, AUC: 0.8243, F1: 0.9230\n",
            "Epoch: 044, Loss: 0.9193, AUC: 0.8272, F1: 0.9169\n",
            "Epoch: 045, Loss: 0.9096, AUC: 0.8197, F1: 0.9348\n",
            "Epoch: 046, Loss: 0.9026, AUC: 0.8260, F1: 0.9006\n",
            "Epoch: 047, Loss: 0.9022, AUC: 0.8255, F1: 0.9286\n",
            "Epoch: 048, Loss: 0.8848, AUC: 0.8232, F1: 0.9289\n",
            "Epoch: 049, Loss: 0.8721, AUC: 0.8265, F1: 0.9050\n",
            "Epoch: 050, Loss: 0.8740, AUC: 0.8178, F1: 0.9327\n",
            "Epoch: 051, Loss: 0.8643, AUC: 0.8274, F1: 0.9098\n",
            "Epoch: 052, Loss: 0.8499, AUC: 0.8262, F1: 0.9215\n",
            "Epoch: 053, Loss: 0.8442, AUC: 0.8258, F1: 0.9325\n",
            "Epoch: 054, Loss: 0.8390, AUC: 0.8289, F1: 0.9085\n",
            "Epoch: 055, Loss: 0.8337, AUC: 0.8291, F1: 0.9284\n",
            "Epoch: 056, Loss: 0.8213, AUC: 0.8330, F1: 0.9292\n",
            "Epoch: 057, Loss: 0.8153, AUC: 0.8306, F1: 0.9164\n",
            "Epoch: 058, Loss: 0.8084, AUC: 0.8313, F1: 0.9322\n",
            "Epoch: 059, Loss: 0.8011, AUC: 0.8316, F1: 0.9168\n",
            "Epoch: 060, Loss: 0.7921, AUC: 0.8286, F1: 0.9355\n",
            "Epoch: 061, Loss: 0.7865, AUC: 0.8319, F1: 0.9142\n",
            "Epoch: 062, Loss: 0.7801, AUC: 0.8298, F1: 0.9306\n",
            "Epoch: 063, Loss: 0.7729, AUC: 0.8314, F1: 0.9310\n",
            "Epoch: 064, Loss: 0.7667, AUC: 0.8326, F1: 0.9187\n",
            "Epoch: 065, Loss: 0.7576, AUC: 0.8301, F1: 0.9323\n",
            "Epoch: 066, Loss: 0.7534, AUC: 0.8320, F1: 0.9274\n",
            "Epoch: 067, Loss: 0.7482, AUC: 0.8339, F1: 0.9274\n",
            "Epoch: 068, Loss: 0.7446, AUC: 0.8350, F1: 0.9222\n",
            "Epoch: 069, Loss: 0.7369, AUC: 0.8252, F1: 0.9395\n",
            "Epoch: 070, Loss: 0.7352, AUC: 0.8379, F1: 0.9123\n",
            "Epoch: 071, Loss: 0.7299, AUC: 0.8293, F1: 0.9378\n",
            "Epoch: 072, Loss: 0.7216, AUC: 0.8360, F1: 0.9290\n",
            "Epoch: 073, Loss: 0.7156, AUC: 0.8369, F1: 0.9279\n",
            "Epoch: 074, Loss: 0.7145, AUC: 0.8311, F1: 0.9328\n",
            "Epoch: 075, Loss: 0.7093, AUC: 0.8303, F1: 0.9298\n",
            "Epoch: 076, Loss: 0.7064, AUC: 0.8296, F1: 0.9324\n",
            "Epoch: 077, Loss: 0.7043, AUC: 0.8384, F1: 0.9209\n",
            "Epoch: 078, Loss: 0.6950, AUC: 0.8288, F1: 0.9365\n",
            "Epoch: 079, Loss: 0.6899, AUC: 0.8341, F1: 0.9332\n",
            "Epoch: 080, Loss: 0.6826, AUC: 0.8389, F1: 0.9194\n",
            "Epoch: 081, Loss: 0.6843, AUC: 0.8322, F1: 0.9389\n",
            "Epoch: 082, Loss: 0.6763, AUC: 0.8329, F1: 0.9334\n",
            "Epoch: 083, Loss: 0.6729, AUC: 0.8386, F1: 0.9219\n",
            "Epoch: 084, Loss: 0.6717, AUC: 0.8286, F1: 0.9383\n",
            "Epoch: 085, Loss: 0.6691, AUC: 0.8321, F1: 0.9296\n",
            "Epoch: 086, Loss: 0.6649, AUC: 0.8376, F1: 0.9251\n",
            "Epoch: 087, Loss: 0.6613, AUC: 0.8325, F1: 0.9364\n",
            "Epoch: 088, Loss: 0.6583, AUC: 0.8364, F1: 0.9322\n",
            "Epoch: 089, Loss: 0.6552, AUC: 0.8396, F1: 0.9281\n",
            "Epoch: 091, Loss: 0.6448, AUC: 0.8347, F1: 0.9367\n",
            "Epoch: 092, Loss: 0.6424, AUC: 0.8407, F1: 0.9243\n",
            "Epoch: 093, Loss: 0.6421, AUC: 0.8314, F1: 0.9386\n",
            "Epoch: 094, Loss: 0.6416, AUC: 0.8406, F1: 0.9278\n",
            "Epoch: 095, Loss: 0.6339, AUC: 0.8359, F1: 0.9324\n",
            "Epoch: 096, Loss: 0.6392, AUC: 0.8351, F1: 0.9323\n",
            "Epoch: 097, Loss: 0.6311, AUC: 0.8350, F1: 0.9315\n",
            "Epoch: 098, Loss: 0.6243, AUC: 0.8363, F1: 0.9336\n",
            "Epoch: 100, Loss: 0.6241, AUC: 0.8360, F1: 0.9339\n",
            "Training completed on TPU in 957.76 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-fMDZ-ZqM5KD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}